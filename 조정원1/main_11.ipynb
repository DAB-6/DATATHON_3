{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02fa00e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì „ì²´ ë°ì´í„° ì¤‘ Y=1 (ë…¸ê²¬ ë˜ëŠ” ì•Œë ˆë¥´ê¸°) ê·¸ë£¹ ê°œìˆ˜: 32737\n",
      "âœ… ì „ì²´ ë°ì´í„° ì¤‘ Y=0 (ê±´ê°•í•œ) ê·¸ë£¹ ê°œìˆ˜: 16305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\10865853.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_model['pet_allergen_list'].fillna('None', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"pet_food_customer_orders.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# í•„ìš”í•œ ì—´ ì„ íƒ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì´ì „ê³¼ ë™ì¼)\n",
    "df_model = df[[\n",
    "    'pet_life_stage_at_order',  # ë…¸ê²¬ ì—¬ë¶€\n",
    "    'pet_allergen_list',        # ì•Œë ˆë¥´ê¸° ì—¬ë¶€\n",
    "    'total_web_sessions',       # ì´ ì›¹ ì„¸ì…˜\n",
    "    'total_minutes_on_website'  # ì´ ì›¹ì‚¬ì´íŠ¸ ì²´ë¥˜ ì‹œê°„\n",
    "]].copy()\n",
    "\n",
    "df_model['pet_allergen_list'].fillna('None', inplace=True)\n",
    "df_model['pet_allergen_list'].replace('Null & Default', 'None', inplace=True)\n",
    "df_model[['total_web_sessions', 'total_minutes_on_website']] = \\\n",
    "    df_model[['total_web_sessions', 'total_minutes_on_website']].fillna(0)\n",
    "\n",
    "# --- ìƒˆë¡œìš´ Y ë³€ìˆ˜ ì •ì˜ ---\n",
    "# ğŸŒŸ Y = 1 (íƒ€ê²Ÿ ê·¸ë£¹): ë…¸ê²¬(mature)ì´ê±°ë‚˜ ì•Œë ˆë¥´ê¸°ê°€ ìˆëŠ” ê²½ìš°\n",
    "is_mature = (df_model['pet_life_stage_at_order'] == 'mature')\n",
    "has_allergy = (df_model['pet_allergen_list'] != 'None')\n",
    "df_model['Y'] = (is_mature | has_allergy).astype(int)\n",
    "\n",
    "# ğŸŒŸ Y = 0 (ëŒ€ì¡° ê·¸ë£¹): ë…¸ê²¬ë„ ì•„ë‹ˆê³  ì•Œë ˆë¥´ê¸°ë„ ì—†ëŠ” 'ê±´ê°•í•œ' ê²½ìš°\n",
    "# Y=0ì„ ëª…ì‹œì ìœ¼ë¡œ ì •ì˜í•  í•„ìš” ì—†ì´, Y=1ì´ ì•„ë‹Œ ëª¨ë“  ë°ì´í„°ê°€ Y=0ì´ ë©ë‹ˆë‹¤.\n",
    "# ì¦‰, (not is_mature) & (not has_allergy) ì¸ ê²½ìš°ê°€ Y=0ì…ë‹ˆë‹¤.\n",
    "\n",
    "print(f\"âœ… ì „ì²´ ë°ì´í„° ì¤‘ Y=1 (ë…¸ê²¬ ë˜ëŠ” ì•Œë ˆë¥´ê¸°) ê·¸ë£¹ ê°œìˆ˜: {df_model['Y'].sum()}\")\n",
    "print(f\"âœ… ì „ì²´ ë°ì´í„° ì¤‘ Y=0 (ê±´ê°•í•œ) ê·¸ë£¹ ê°œìˆ˜: {len(df_model) - df_model['Y'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a0b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "âœ… ì†Œìˆ˜ ê·¸ë£¹ í¬ê¸°: 16305\n",
      "âœ… ìµœì¢… ê· í˜• ì¡íŒ ë°ì´í„° í¬ê¸° (1:1 ë¹„ìœ¨): 32610\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. Target Group (Y=1)ê³¼ Control Group (Y=0) ë°ì´í„° ë¶„ë¦¬\n",
    "df_target = df_model[df_model['Y'] == 1]\n",
    "df_control = df_model[df_model['Y'] == 0]\n",
    "\n",
    "# 2. ì†Œìˆ˜ ê·¸ë£¹ì˜ í¬ê¸°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •\n",
    "if len(df_target) <= len(df_control):\n",
    "    n_minority = len(df_target)\n",
    "    df_majority = df_control\n",
    "    df_minority = df_target\n",
    "else:\n",
    "    n_minority = len(df_control)\n",
    "    df_majority = df_target\n",
    "    df_minority = df_control\n",
    "\n",
    "# 3. ë‹¤ìˆ˜ ê·¸ë£¹ì„ ì†Œìˆ˜ ê·¸ë£¹ì˜ í¬ê¸°ì— ë§ê²Œ ëœë¤ ìƒ˜í”Œë§ (1:1 ë¶„í¬)\n",
    "# random_stateë¥¼ ì„¤ì •í•˜ì—¬ ê²°ê³¼ì˜ ì¬í˜„ì„±ì„ í™•ë³´\n",
    "df_majority_sampled = df_majority.sample(n=n_minority, random_state=42)\n",
    "\n",
    "# 4. ìƒ˜í”Œë§ëœ ë‘ ê·¸ë£¹ ë°ì´í„°ë¥¼ í•©ì¹˜ê¸°\n",
    "df_balanced = pd.concat([df_minority, df_majority_sampled])\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"âœ… ì†Œìˆ˜ ê·¸ë£¹ í¬ê¸°: {n_minority}\")\n",
    "print(f\"âœ… ìµœì¢… ê· í˜• ì¡íŒ ë°ì´í„° í¬ê¸° (1:1 ë¹„ìœ¨): {len(df_balanced)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜(X)ì™€ ì¢…ì† ë³€ìˆ˜(Y) ì •ì˜\n",
    "X = df_balanced[['total_web_sessions', 'total_minutes_on_website']]\n",
    "Y = df_balanced['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca30bb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690489\n",
      "         Iterations 4\n",
      "### ğŸ“Š ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ ê²°ê³¼ (Statsmodels Logit) ###\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                32610\n",
      "Model:                          Logit   Df Residuals:                    32607\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 11 Nov 2025   Pseudo R-squ.:                0.003835\n",
      "Time:                        14:26:24   Log-Likelihood:                -22517.\n",
      "converged:                       True   LL-Null:                       -22604.\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.234e-38\n",
      "============================================================================================\n",
      "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                       -0.1104      0.014     -7.640      0.000      -0.139      -0.082\n",
      "total_web_sessions           0.0204      0.002     12.737      0.000       0.017       0.024\n",
      "total_minutes_on_website    -0.0001   1.83e-05     -6.881      0.000      -0.000      -9e-05\n",
      "============================================================================================\n",
      "\n",
      "### âœ¨ Odds Ratio (ìŠ¹ì‚°ë¹„) ###\n",
      "ìƒìˆ˜í•­ (Intercept) ìŠ¹ì‚°ë¹„: 0.8955\n",
      "ì´ ì›¹ ì„¸ì…˜ ìŠ¹ì‚°ë¹„: 1.0207\n",
      "ì´ ì²´ë¥˜ ì‹œê°„ ìŠ¹ì‚°ë¹„: 0.9999\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ìƒìˆ˜í•­(Intercept) ì¶”ê°€\n",
    "X = sm.add_constant(X) \n",
    "\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ì í•© (fit)\n",
    "logit_model = sm.Logit(Y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"### ğŸ“Š ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ ê²°ê³¼ (Statsmodels Logit) ###\")\n",
    "print(result.summary())\n",
    "\n",
    "# ìŠ¹ì‚°ë¹„(Odds Ratio) í•´ì„ì„ ìœ„í•œ ì§€ìˆ˜(Exponential) ë³€í™˜\n",
    "odds_ratios = np.exp(result.params)\n",
    "print(\"\\n### âœ¨ Odds Ratio (ìŠ¹ì‚°ë¹„) ###\")\n",
    "print(f\"ìƒìˆ˜í•­ (Intercept) ìŠ¹ì‚°ë¹„: {odds_ratios['const']:.4f}\")\n",
    "print(f\"ì´ ì›¹ ì„¸ì…˜ ìŠ¹ì‚°ë¹„: {odds_ratios['total_web_sessions']:.4f}\")\n",
    "print(f\"ì´ ì²´ë¥˜ ì‹œê°„ ìŠ¹ì‚°ë¹„: {odds_ratios['total_minutes_on_website']:.4f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f48cd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\3897191035.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_model['pet_allergen_list'].fillna('None', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"pet_food_customer_orders.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- í•„ìš”í•œ ì—´ ì„ íƒ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ---\n",
    "df_model = df[[\n",
    "    'pet_life_stage_at_order',  # ë…¸ê²¬ ì—¬ë¶€\n",
    "    'pet_allergen_list',        # ì•Œë ˆë¥´ê¸° ì—¬ë¶€\n",
    "    'total_web_sessions',       # ì›¹ ì„¸ì…˜\n",
    "    'total_minutes_on_website', # ì²´ë¥˜ ì‹œê°„\n",
    "    'pet_food_tier'             # â­ ì‹ ê·œ ë³€ìˆ˜ ì¶”ê°€\n",
    "]].copy()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì´ì „ê³¼ ë™ì¼)\n",
    "df_model['pet_allergen_list'].fillna('None', inplace=True)\n",
    "df_model['pet_allergen_list'].replace('Null & Default', 'None', inplace=True)\n",
    "df_model[['total_web_sessions', 'total_minutes_on_website']] = \\\n",
    "    df_model[['total_web_sessions', 'total_minutes_on_website']].fillna(0)\n",
    "\n",
    "# â­ Y ë³€ìˆ˜ ì •ì˜ (ë…¸ê²¬ ë˜ëŠ” ì•Œë ˆë¥´ê¸° = 1)\n",
    "is_mature = (df_model['pet_life_stage_at_order'] == 'mature')\n",
    "has_allergy = (df_model['pet_allergen_list'] != 'None')\n",
    "df_model['Y'] = (is_mature | has_allergy).astype(int)\n",
    "\n",
    "# --- ğŸ’¡ ë³€ìˆ˜ ë³€í™˜ ë° ìƒì„± (Feature Engineering) ---\n",
    "# 1. ë¡œê·¸ ë³€í™˜ (ë¡œê·¸(1 + X) ì‚¬ìš©)\n",
    "df_model['log_sessions'] = np.log1p(df_model['total_web_sessions'])\n",
    "df_model['log_minutes'] = np.log1p(df_model['total_minutes_on_website'])\n",
    "\n",
    "# 2. ì„¸ì…˜ë‹¹ í‰ê·  ì²´ë¥˜ ì‹œê°„ ìƒì„±\n",
    "# total_web_sessionsê°€ 0ì¸ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë‚˜ëˆ„ê¸° ì˜¤ë¥˜ ë°©ì§€\n",
    "df_model['avg_min_per_session'] = np.where(\n",
    "    df_model['total_web_sessions'] > 0,\n",
    "    df_model['total_minutes_on_website'] / df_model['total_web_sessions'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# 3. ë²”ì£¼í˜• ë³€ìˆ˜ ë”ë¯¸í™” (pet_food_tier)\n",
    "# 'superpremium', 'premium', 'mid' ë“±ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°,\n",
    "# Get Dummiesë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ë”ë¯¸ ë³€ìˆ˜ ìƒì„± ë° ì›ë³¸ ë³€ìˆ˜ ì œê±°\n",
    "df_dummies = pd.get_dummies(df_model['pet_food_tier'], prefix='tier', drop_first=True)\n",
    "df_model = pd.concat([df_model, df_dummies], axis=1)\n",
    "\n",
    "# print(df_model.head()) # ë³€ìˆ˜ ìƒì„± í™•ì¸ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59906a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê· í˜• ì¡íŒ ìµœì¢… ë°ì´í„° í¬ê¸° (1:1 ë¹„ìœ¨): 32610\n",
      "--------------------------------------------------\n",
      "### ğŸ“Š ë³€í™˜/ì¶”ê°€ ë³€ìˆ˜ ì ìš© ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ ê²°ê³¼ ###\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   No. Observations:                32610\n",
      "Model:                          Logit   Df Residuals:                    32604\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 11 Nov 2025   Pseudo R-squ.:                0.003115\n",
      "Time:                        14:33:25   Log-Likelihood:                -22533.\n",
      "converged:                       True   LL-Null:                       -22604.\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.201e-28\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -0.2654      0.036     -7.423      0.000      -0.335      -0.195\n",
      "log_sessions            0.1531      0.023      6.769      0.000       0.109       0.197\n",
      "log_minutes            -0.0140      0.013     -1.087      0.277      -0.039       0.011\n",
      "avg_min_per_session    -0.0001      0.000     -0.598      0.550      -0.000       0.000\n",
      "tier_premium            0.1145      0.035      3.293      0.001       0.046       0.183\n",
      "tier_superpremium       0.0788      0.027      2.926      0.003       0.026       0.132\n",
      "=======================================================================================\n",
      "\n",
      "### âœ¨ Odds Ratio (ìŠ¹ì‚°ë¹„) ###\n",
      "const                  0.766896\n",
      "log_sessions           1.165469\n",
      "log_minutes            0.986132\n",
      "avg_min_per_session    0.999890\n",
      "tier_premium           1.121269\n",
      "tier_superpremium      1.081984\n",
      "dtype: float64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 1:1 ë¶„í¬ë¥¼ ìœ„í•œ ì–¸ë”ìƒ˜í”Œë§ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "df_target = df_model[df_model['Y'] == 1]\n",
    "df_control = df_model[df_model['Y'] == 0]\n",
    "\n",
    "# ì†Œìˆ˜ ê·¸ë£¹ì˜ í¬ê¸°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒ˜í”Œë§\n",
    "if len(df_target) <= len(df_control):\n",
    "    n_minority = len(df_target)\n",
    "    df_majority = df_control\n",
    "    df_minority = df_target\n",
    "else:\n",
    "    n_minority = len(df_control)\n",
    "    df_majority = df_target\n",
    "    df_minority = df_control\n",
    "\n",
    "df_majority_sampled = df_majority.sample(n=n_minority, random_state=42)\n",
    "df_balanced = pd.concat([df_minority, df_majority_sampled])\n",
    "\n",
    "print(f\"âœ… ê· í˜• ì¡íŒ ìµœì¢… ë°ì´í„° í¬ê¸° (1:1 ë¹„ìœ¨): {len(df_balanced)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- ğŸ’¡ ë…ë¦½ ë³€ìˆ˜(X) ì¬ì •ì˜ ---\n",
    "# ë³€í™˜ëœ ì›¹ í™œë™ ë³€ìˆ˜ì™€ ë”ë¯¸ ë³€ìˆ˜ë¥¼ í¬í•¨\n",
    "X_cols = [\n",
    "    'log_sessions', \n",
    "    'log_minutes', \n",
    "    'avg_min_per_session'\n",
    "] + [col for col in df_balanced.columns if col.startswith('tier_')]\n",
    "\n",
    "X = df_balanced[X_cols]\n",
    "Y = df_balanced['Y']\n",
    "\n",
    "# ìƒìˆ˜í•­(Intercept) ì¶”ê°€ ë° ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ì í•©\n",
    "X = sm.add_constant(X) \n",
    "X = X.astype(float)\n",
    "logit_model = sm.Logit(Y, X)\n",
    "result = logit_model.fit(disp=False) # disp=False: í•™ìŠµ ê³¼ì • ë©”ì‹œì§€ ìƒëµ\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"### ğŸ“Š ë³€í™˜/ì¶”ê°€ ë³€ìˆ˜ ì ìš© ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ ê²°ê³¼ ###\")\n",
    "print(result.summary())\n",
    "\n",
    "# ìŠ¹ì‚°ë¹„(Odds Ratio) í•´ì„\n",
    "odds_ratios = np.exp(result.params)\n",
    "print(\"\\n### âœ¨ Odds Ratio (ìŠ¹ì‚°ë¹„) ###\")\n",
    "print(odds_ratios)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0678c7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\840882787.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_model['pet_food_tier'].fillna('missing', inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\840882787.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_model['pet_food_tier'].replace('Null & Default', 'missing', inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\840882787.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_model['pet_allergen_list'].fillna('None', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:36:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"pet_food_customer_orders.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- 1. ì´ì „ ë‹¨ê³„ì—ì„œ ì •ì˜ëœ Y, ë³€í™˜ëœ ë³€ìˆ˜, ë”ë¯¸ ë³€ìˆ˜ ìƒì„± ì½”ë“œ ì¬ì‹¤í–‰ ---\n",
    "\n",
    "df_model = df[[\n",
    "    'pet_life_stage_at_order', 'pet_allergen_list', 'total_web_sessions',\n",
    "    'total_minutes_on_website', 'pet_food_tier',\n",
    "    'pet_breed_size', 'neutered', 'pet_health_issue_list'\n",
    "]].copy()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ë° 'Null & Default' ì²˜ë¦¬\n",
    "df_model['pet_food_tier'].fillna('missing', inplace=True)\n",
    "df_model['pet_food_tier'].replace('Null & Default', 'missing', inplace=True)\n",
    "df_model['pet_allergen_list'].fillna('None', inplace=True)\n",
    "df_model['pet_allergen_list'].replace('Null & Default', 'None', inplace=True)\n",
    "df_model[['total_web_sessions', 'total_minutes_on_website']] = \\\n",
    "    df_model[['total_web_sessions', 'total_minutes_on_website']].fillna(0)\n",
    "\n",
    "# Y ë³€ìˆ˜ ì •ì˜ (ë…¸ê²¬ ë˜ëŠ” ì•Œë ˆë¥´ê¸° = 1)\n",
    "is_mature = (df_model['pet_life_stage_at_order'] == 'mature')\n",
    "has_allergy = (df_model['pet_allergen_list'] != 'None')\n",
    "df_model['Y'] = (is_mature | has_allergy).astype(int)\n",
    "\n",
    "# ë³€ìˆ˜ ë³€í™˜ ë° ë”ë¯¸ ë³€ìˆ˜ ìƒì„±\n",
    "df_model['log_sessions'] = np.log1p(df_model['total_web_sessions'])\n",
    "\n",
    "df_dummies_tier = pd.get_dummies(df_model['pet_food_tier'], prefix='tier', drop_first=True)\n",
    "df_dummies_size = pd.get_dummies(df_model['pet_breed_size'], prefix='size', drop_first=True)\n",
    "\n",
    "df_model['is_neutered'] = (df_model['neutered'].astype(str).str.upper() == 'TRUE').astype(int)\n",
    "df_model['has_other_health_issue'] = df_model['pet_health_issue_list'].apply(\n",
    "    lambda x: 1 if pd.notna(x) and str(x) not in ['None', 'Null & Default', ''] else 0\n",
    ")\n",
    "\n",
    "df_model = pd.concat([df_model, df_dummies_tier, df_dummies_size], axis=1)\n",
    "\n",
    "# --- 2. 1:1 ë¶„í¬ë¥¼ ìœ„í•œ ì–¸ë”ìƒ˜í”Œë§ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "df_target = df_model[df_model['Y'] == 1]\n",
    "df_control = df_model[df_model['Y'] == 0]\n",
    "\n",
    "if len(df_target) <= len(df_control):\n",
    "    n_minority = len(df_target)\n",
    "    df_majority = df_control\n",
    "    df_minority = df_target\n",
    "else:\n",
    "    n_minority = len(df_control)\n",
    "    df_majority = df_target\n",
    "    df_minority = df_control\n",
    "\n",
    "df_majority_sampled = df_majority.sample(n=n_minority, random_state=42)\n",
    "df_balanced = pd.concat([df_minority, df_majority_sampled])\n",
    "\n",
    "# --- 3. XGBoostë¥¼ ìœ„í•œ ë…ë¦½ ë³€ìˆ˜(X) ìµœì¢… ì •ì˜ ---\n",
    "X_cols_final = [\n",
    "    'log_sessions', 'is_neutered', 'has_other_health_issue',\n",
    "    'tier_premium', 'tier_superpremium', 'tier_missing', \n",
    "    'size_medium', 'size_small', 'size_Null & Default', 'size_missing'\n",
    "]\n",
    "\n",
    "X_cols_final = [col for col in X_cols_final if col in df_balanced.columns]\n",
    "\n",
    "X = df_balanced[X_cols_final].astype(float)\n",
    "Y = df_balanced['Y']\n",
    "\n",
    "# í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ì„ ìœ„í•´ í•„ìˆ˜)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    ")\n",
    "\n",
    "# 4. XGBoost ëª¨ë¸ í•™ìŠµ\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_estimators=100, # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "    max_depth=3       # íŠ¸ë¦¬ ê¹Šì´ (ê³¼ì í•© ë°©ì§€)\n",
    ")\n",
    "\n",
    "print(\"âœ… XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "xgb_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "953eaa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„ (Accuracy): 0.6352\n",
      "ROC-AUC ì ìˆ˜: 0.6714\n",
      "\n",
      "ë¶„ë¥˜ ë³´ê³ ì„œ (Classification Report):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62      3261\n",
      "           1       0.63      0.67      0.65      3261\n",
      "\n",
      "    accuracy                           0.64      6522\n",
      "   macro avg       0.64      0.64      0.63      6522\n",
      "weighted avg       0.64      0.64      0.63      6522\n",
      "\n",
      "\n",
      "### ğŸ”‘ ë³€ìˆ˜ ì¤‘ìš”ë„ ìˆœìœ„ (Feature Importance) ###\n",
      "is_neutered               0.792006\n",
      "has_other_health_issue    0.109410\n",
      "tier_premium              0.032367\n",
      "tier_superpremium         0.020638\n",
      "size_small                0.018637\n",
      "log_sessions              0.015226\n",
      "size_medium               0.011717\n",
      "dtype: float32\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "Y_pred = xgb_model.predict(X_test)\n",
    "Y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ ì¶œë ¥\n",
    "print(f\"ì •í™•ë„ (Accuracy): {accuracy_score(Y_test, Y_pred):.4f}\")\n",
    "print(f\"ROC-AUC ì ìˆ˜: {roc_auc_score(Y_test, Y_proba):.4f}\")\n",
    "print(\"\\në¶„ë¥˜ ë³´ê³ ì„œ (Classification Report):\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# ë³€ìˆ˜ ì¤‘ìš”ë„ (Feature Importance) í™•ì¸\n",
    "importance = pd.Series(xgb_model.feature_importances_, index=X.columns)\n",
    "importance = importance.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n### ğŸ”‘ ë³€ìˆ˜ ì¤‘ìš”ë„ ìˆœìœ„ (Feature Importance) ###\")\n",
    "print(importance)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7339211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Target Group (ë…¸ë ¹ê²¬/ì•Œë ˆë¥´ê¸°) ìˆ˜: 32737\n",
      "âœ… Control Group (ì¼ë°˜) ìˆ˜: 16305\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\397729491.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_analysis['pet_allergen_list'].fillna('None', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats # T-ê²€ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"pet_food_customer_orders.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- íƒ€ê²Ÿ ë³€ìˆ˜ ë° ë³€ìˆ˜ ì¤€ë¹„ ---\n",
    "df_analysis = df.copy()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì›¹ í™œë™ ë³€ìˆ˜ì™€ ì•Œë ˆë¥´ê¸°/ë…¸ë ¹ê²¬ ë³€ìˆ˜)\n",
    "df_analysis['pet_allergen_list'].fillna('None', inplace=True)\n",
    "df_analysis['pet_allergen_list'].replace('Null & Default', 'None', inplace=True)\n",
    "df_analysis[['total_web_sessions', 'total_minutes_on_website']] = \\\n",
    "    df_analysis[['total_web_sessions', 'total_minutes_on_website']].fillna(0)\n",
    "\n",
    "# â­ Y ë³€ìˆ˜ ì •ì˜ â­\n",
    "# Target Group (Y=1): ë…¸ë ¹ê²¬(mature)ì´ê±°ë‚˜ ì•Œë ˆë¥´ê¸°ê°€ ìˆëŠ” ê²½ìš°\n",
    "is_mature = (df_analysis['pet_life_stage_at_order'] == 'mature')\n",
    "has_allergy = (df_analysis['pet_allergen_list'] != 'None')\n",
    "df_analysis['Target_Group'] = (is_mature | has_allergy).astype(int)\n",
    "\n",
    "# 1. ë…¸ë ¹ê²¬/ì•Œë ˆë¥´ê¸° ê·¸ë£¹ (Y=1)\n",
    "group_target = df_analysis[df_analysis['Target_Group'] == 1]\n",
    "# 2. ì¼ë°˜ ê·¸ë£¹ (Y=0)\n",
    "group_control = df_analysis[df_analysis['Target_Group'] == 0]\n",
    "\n",
    "print(f\"âœ… Target Group (ë…¸ë ¹ê²¬/ì•Œë ˆë¥´ê¸°) ìˆ˜: {len(group_target)}\")\n",
    "print(f\"âœ… Control Group (ì¼ë°˜) ìˆ˜: {len(group_control)}\")\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "328f2d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ğŸ“Š ê·¸ë£¹ë³„ ì›¹ í™œë™ ê¸°ìˆ í†µê³„ëŸ‰ ###\n",
      "\n",
      "[ì´ ì›¹ ì„¸ì…˜ (total_web_sessions)]\n",
      "              count      mean  median        std  min  max\n",
      "Target_Group                                              \n",
      "ì¼ë°˜ ê·¸ë£¹ (Y=0)   16305  7.192150     4.0   8.923336    0  108\n",
      "íƒ€ê²Ÿ ê·¸ë£¹ (Y=1)   32737  8.345878     5.0  10.089429    0  124\n",
      "\n",
      "[ì´ ì›¹ ì²´ë¥˜ ì‹œê°„ (total_minutes_on_website)]\n",
      "              count        mean  median         std  min    max\n",
      "Target_Group                                                   \n",
      "ì¼ë°˜ ê·¸ë£¹ (Y=0)   16305  372.165164    52.0  798.097090    0  17318\n",
      "íƒ€ê²Ÿ ê·¸ë£¹ (Y=1)   32737  389.271222    62.0  833.859941    0  23734\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"### ğŸ“Š ê·¸ë£¹ë³„ ì›¹ í™œë™ ê¸°ìˆ í†µê³„ëŸ‰ ###\")\n",
    "\n",
    "# ì´ ì›¹ ì„¸ì…˜\n",
    "stats_sessions = df_analysis.groupby('Target_Group')['total_web_sessions'].agg(\n",
    "    ['count', 'mean', 'median', 'std', 'min', 'max']\n",
    ")\n",
    "print(\"\\n[ì´ ì›¹ ì„¸ì…˜ (total_web_sessions)]\")\n",
    "print(stats_sessions.rename(index={0: 'ì¼ë°˜ ê·¸ë£¹ (Y=0)', 1: 'íƒ€ê²Ÿ ê·¸ë£¹ (Y=1)'}))\n",
    "\n",
    "# ì´ ì²´ë¥˜ ì‹œê°„\n",
    "stats_minutes = df_analysis.groupby('Target_Group')['total_minutes_on_website'].agg(\n",
    "    ['count', 'mean', 'median', 'std', 'min', 'max']\n",
    ")\n",
    "print(\"\\n[ì´ ì›¹ ì²´ë¥˜ ì‹œê°„ (total_minutes_on_website)]\")\n",
    "print(stats_minutes.rename(index={0: 'ì¼ë°˜ ê·¸ë£¹ (Y=0)', 1: 'íƒ€ê²Ÿ ê·¸ë£¹ (Y=1)'}))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de01f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ğŸ”¬ ë…ë¦½í‘œë³¸ T-ê²€ì • ê²°ê³¼ (í‰ê·  ì°¨ì´) ###\n",
      "\n",
      "[ì´ ì›¹ ì„¸ì…˜ í‰ê·  ì°¨ì´]\n",
      "T-statistic: 12.9047\n",
      "P-value: 0.00000\n",
      "â¡ï¸ í•´ì„: P-valueê°€ 0.05 ë¯¸ë§Œì´ë¯€ë¡œ, ë‘ ê·¸ë£¹ì˜ ì›¹ ì„¸ì…˜ í‰ê· ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ë‹¤ë¦…ë‹ˆë‹¤.\n",
      "\n",
      "[ì´ ì›¹ ì²´ë¥˜ ì‹œê°„ í‰ê·  ì°¨ì´]\n",
      "T-statistic: 2.2028\n",
      "P-value: 0.02762\n",
      "â¡ï¸ í•´ì„: P-valueê°€ 0.05 ë¯¸ë§Œì´ë¯€ë¡œ, ë‘ ê·¸ë£¹ì˜ ì›¹ ì²´ë¥˜ ì‹œê°„ í‰ê· ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ë‹¤ë¦…ë‹ˆë‹¤.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"### ğŸ”¬ ë…ë¦½í‘œë³¸ T-ê²€ì • ê²°ê³¼ (í‰ê·  ì°¨ì´) ###\")\n",
    "\n",
    "# A. ì´ ì›¹ ì„¸ì…˜ T-ê²€ì •\n",
    "t_stat_sessions, p_val_sessions = stats.ttest_ind(\n",
    "    group_target['total_web_sessions'], \n",
    "    group_control['total_web_sessions'], \n",
    "    equal_var=False # Welch's T-test (ë“±ë¶„ì‚°ì„± ê°€ì •í•˜ì§€ ì•ŠìŒ)\n",
    ")\n",
    "\n",
    "print(\"\\n[ì´ ì›¹ ì„¸ì…˜ í‰ê·  ì°¨ì´]\")\n",
    "print(f\"T-statistic: {t_stat_sessions:.4f}\")\n",
    "print(f\"P-value: {p_val_sessions:.5f}\")\n",
    "if p_val_sessions < 0.05:\n",
    "    print(\"â¡ï¸ í•´ì„: P-valueê°€ 0.05 ë¯¸ë§Œì´ë¯€ë¡œ, ë‘ ê·¸ë£¹ì˜ ì›¹ ì„¸ì…˜ í‰ê· ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ë‹¤ë¦…ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"â¡ï¸ í•´ì„: P-valueê°€ 0.05 ì´ìƒì´ë¯€ë¡œ, ë‘ ê·¸ë£¹ì˜ ì›¹ ì„¸ì…˜ í‰ê·  ì°¨ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# B. ì´ ì²´ë¥˜ ì‹œê°„ T-ê²€ì •\n",
    "t_stat_minutes, p_val_minutes = stats.ttest_ind(\n",
    "    group_target['total_minutes_on_website'], \n",
    "    group_control['total_minutes_on_website'], \n",
    "    equal_var=False\n",
    ")\n",
    "\n",
    "print(\"\\n[ì´ ì›¹ ì²´ë¥˜ ì‹œê°„ í‰ê·  ì°¨ì´]\")\n",
    "print(f\"T-statistic: {t_stat_minutes:.4f}\")\n",
    "print(f\"P-value: {p_val_minutes:.5f}\")\n",
    "if p_val_minutes < 0.05:\n",
    "    print(\"â¡ï¸ í•´ì„: P-valueê°€ 0.05 ë¯¸ë§Œì´ë¯€ë¡œ, ë‘ ê·¸ë£¹ì˜ ì›¹ ì²´ë¥˜ ì‹œê°„ í‰ê· ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ë‹¤ë¦…ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"â¡ï¸ í•´ì„: P-valueê°€ 0.05 ì´ìƒì´ë¯€ë¡œ, ë‘ ê·¸ë£¹ì˜ ì›¹ ì²´ë¥˜ ì‹œê°„ í‰ê·  ì°¨ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d65eb339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\702703663.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_analysis['pet_allergen_list'].fillna('None', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì¢… ë¶„ì„ ëŒ€ìƒ ê·¸ë£¹ë³„ ê°œìˆ˜:\n",
      "Final_Group\n",
      "A. ë…¸ë ¹ê²¬ ê·¸ë£¹     21979\n",
      "B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹     3604\n",
      "D. ì¼ë°˜ ê·¸ë£¹      16305\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"pet_food_customer_orders.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- íƒ€ê²Ÿ ë³€ìˆ˜ ë° ë³€ìˆ˜ ì¤€ë¹„ ---\n",
    "df_analysis = df.copy()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì›¹ í™œë™ ë³€ìˆ˜ì™€ ì•Œë ˆë¥´ê¸°/ë…¸ë ¹ê²¬ ë³€ìˆ˜)\n",
    "df_analysis['pet_allergen_list'].fillna('None', inplace=True)\n",
    "df_analysis['pet_allergen_list'].replace('Null & Default', 'None', inplace=True)\n",
    "df_analysis[['total_web_sessions', 'total_minutes_on_website']] = \\\n",
    "    df_analysis[['total_web_sessions', 'total_minutes_on_website']].fillna(0)\n",
    "\n",
    "# â­ 3ê°€ì§€ ê·¸ë£¹ ì •ì˜ â­\n",
    "# 1. ë…¸ë ¹ê²¬ ê·¸ë£¹ (Y=1): mature ì´ë©´ì„œ ì•Œë ˆë¥´ê¸°ê°€ ì—†ëŠ” ê²½ìš°\n",
    "is_mature = (df_analysis['pet_life_stage_at_order'] == 'mature')\n",
    "has_allergy = (df_analysis['pet_allergen_list'] != 'None')\n",
    "\n",
    "# 'Group_Type' ì»¬ëŸ¼ ìƒì„±\n",
    "df_analysis['Group_Type'] = np.select(\n",
    "    [\n",
    "        is_mature & ~has_allergy,   # ì¡°ê±´ 1: ë…¸ë ¹ê²¬(mature)ì´ë©´ì„œ ì•Œë ˆë¥´ê¸°ê°€ ì—†ëŠ” ê²½ìš°\n",
    "        has_allergy & ~is_mature,   # ì¡°ê±´ 2: ì•Œë ˆë¥´ê¸°ê°€ ìˆìœ¼ë©´ì„œ ë…¸ë ¹ê²¬ì´ ì•„ë‹Œ ê²½ìš°\n",
    "        is_mature & has_allergy,    # ì¡°ê±´ 3: ë…¸ë ¹ê²¬ì´ë©´ì„œ ì•Œë ˆë¥´ê¸°ê°€ ìˆëŠ” ê²½ìš°\n",
    "    ],\n",
    "    [\n",
    "        'A. ë…¸ë ¹ê²¬ ê·¸ë£¹', \n",
    "        'B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹', \n",
    "        'C. ë³µí•© ê·¸ë£¹ (ë…¸ë ¹ê²¬ & ì•Œë ˆë¥´ê¸°)'\n",
    "    ],\n",
    "    default='D. ì¼ë°˜ ê·¸ë£¹ (ëª¨ë‘ í•´ë‹¹ ì—†ìŒ)' # ê¸°ë³¸ê°’\n",
    ")\n",
    "\n",
    "# ë¶„ì„ì—ì„œ 'ë³µí•© ê·¸ë£¹'ì€ ì œì™¸í•˜ê³ , ìˆœìˆ˜í•œ 3ê°œ ê·¸ë£¹ì„ ë¹„êµ\n",
    "# ë§Œì•½ 'ë³µí•© ê·¸ë£¹'ê¹Œì§€ í¬í•¨í•˜ì—¬ ë¶„ì„í•˜ë ¤ë©´, ìœ„ì˜ np.select ì¡°ê±´ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œëŠ” ìš”ì²­í•˜ì‹  'ë…¸ë ¹ê²¬', 'ì•Œë ˆë¥´ê¸°', 'ì¼ë°˜' ê·¸ë£¹ì„ ëª…í™•íˆ ë¹„êµí•˜ê¸° ìœ„í•´\n",
    "# ë…¸ë ¹ê²¬ì´ë©´ì„œ ì•Œë ˆë¥´ê¸°ì¸ ê²½ìš°ëŠ” ì œì™¸í•˜ê³  ìˆœìˆ˜ ê·¸ë£¹ì„ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "# ğŸ’¡ ì¬ì •ì˜: ê²¹ì¹˜ëŠ” ê·¸ë£¹ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
    "def categorize_group(row):\n",
    "    is_mature_ = (row['pet_life_stage_at_order'] == 'mature')\n",
    "    has_allergy_ = (row['pet_allergen_list'] != 'None')\n",
    "    \n",
    "    if is_mature_ and has_allergy_:\n",
    "        return 'C. ë³µí•© ê·¸ë£¹' # ë…¸ë ¹ê²¬ì´ë©´ì„œ ì•Œë ˆë¥´ê¸° (ë¶„ì„ ì œì™¸ ë˜ëŠ” ë³„ë„ ê³ ë ¤)\n",
    "    elif is_mature_:\n",
    "        return 'A. ë…¸ë ¹ê²¬ ê·¸ë£¹'\n",
    "    elif has_allergy_:\n",
    "        return 'B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹'\n",
    "    else:\n",
    "        return 'D. ì¼ë°˜ ê·¸ë£¹'\n",
    "\n",
    "df_analysis['Final_Group'] = df_analysis.apply(categorize_group, axis=1)\n",
    "\n",
    "# ë¶„ì„ì— ì‚¬ìš©í•  3ê°œ ê·¸ë£¹ ì„ íƒ\n",
    "target_groups = ['A. ë…¸ë ¹ê²¬ ê·¸ë£¹', 'B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹', 'D. ì¼ë°˜ ê·¸ë£¹']\n",
    "df_filtered = df_analysis[df_analysis['Final_Group'].isin(target_groups)].copy()\n",
    "\n",
    "print(f\"âœ… ìµœì¢… ë¶„ì„ ëŒ€ìƒ ê·¸ë£¹ë³„ ê°œìˆ˜:\")\n",
    "print(df_filtered['Final_Group'].value_counts().sort_index())\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb7642cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ğŸ“Š ê·¸ë£¹ë³„ ì›¹ í™œë™ ê¸°ìˆ í†µê³„ëŸ‰ ###\n",
      "\n",
      "[ì´ ì›¹ ì„¸ì…˜ (total_web_sessions)]\n",
      "             count      mean  median       std  min  max\n",
      "Final_Group                                             \n",
      "A. ë…¸ë ¹ê²¬ ê·¸ë£¹    21979  8.082488     5.0  9.976101    0  124\n",
      "B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹    3604  8.341565     5.0  9.785098    0   73\n",
      "D. ì¼ë°˜ ê·¸ë£¹     16305  7.192150     4.0  8.923336    0  108\n",
      "\n",
      "[ì´ ì›¹ ì²´ë¥˜ ì‹œê°„ (total_minutes_on_website)]\n",
      "             count        mean  median         std  min    max\n",
      "Final_Group                                                   \n",
      "A. ë…¸ë ¹ê²¬ ê·¸ë£¹    21979  374.211065    55.0  849.145445    0  23734\n",
      "B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹    3604  413.411487    70.0  822.256032    0  17365\n",
      "D. ì¼ë°˜ ê·¸ë£¹     16305  372.165164    52.0  798.097090    0  17318\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"### ğŸ“Š ê·¸ë£¹ë³„ ì›¹ í™œë™ ê¸°ìˆ í†µê³„ëŸ‰ ###\")\n",
    "\n",
    "# ì´ ì›¹ ì„¸ì…˜\n",
    "stats_sessions = df_filtered.groupby('Final_Group')['total_web_sessions'].agg(\n",
    "    ['count', 'mean', 'median', 'std', 'min', 'max']\n",
    ").sort_index()\n",
    "\n",
    "print(\"\\n[ì´ ì›¹ ì„¸ì…˜ (total_web_sessions)]\")\n",
    "print(stats_sessions)\n",
    "\n",
    "# ì´ ì²´ë¥˜ ì‹œê°„\n",
    "stats_minutes = df_filtered.groupby('Final_Group')['total_minutes_on_website'].agg(\n",
    "    ['count', 'mean', 'median', 'std', 'min', 'max']\n",
    ").sort_index()\n",
    "\n",
    "print(\"\\n[ì´ ì›¹ ì²´ë¥˜ ì‹œê°„ (total_minutes_on_website)]\")\n",
    "print(stats_minutes)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2a741bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\549736833.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_analysis['pet_allergen_list'].fillna('None', inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\549736833.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_analysis['pet_food_tier'].fillna('missing', inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\549736833.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_analysis['pet_food_tier'].replace('Null & Default', 'missing', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì¢… ë¶„ì„ ëŒ€ìƒ ê·¸ë£¹ë³„ ê°œìˆ˜:\n",
      "Final_Group\n",
      "A. ë…¸ë ¹ê²¬ ê·¸ë£¹     21979\n",
      "B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹     3604\n",
      "D. ì¼ë°˜ ê·¸ë£¹      16305\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
    "file_path = \"pet_food_customer_orders.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- íƒ€ê²Ÿ ë³€ìˆ˜ ë° ë³€ìˆ˜ ì¤€ë¹„ ---\n",
    "df_analysis = df.copy()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "df_analysis['pet_allergen_list'].fillna('None', inplace=True)\n",
    "df_analysis['pet_allergen_list'].replace('Null & Default', 'None', inplace=True)\n",
    "# pet_food_tierì˜ ê²°ì¸¡ì¹˜ ë° Null ê°’ì€ 'missing'ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ê·¸ë£¹ì— í¬í•¨\n",
    "df_analysis['pet_food_tier'].fillna('missing', inplace=True)\n",
    "df_analysis['pet_food_tier'].replace('Null & Default', 'missing', inplace=True)\n",
    "\n",
    "# â­ 3ê°€ì§€ ê·¸ë£¹ ì •ì˜ (ë…¸ë ¹ê²¬ì´ë©´ì„œ ì•Œë ˆë¥´ê¸°ì¸ ë³µí•© ê·¸ë£¹ì€ ì œì™¸) â­\n",
    "def categorize_group(row):\n",
    "    is_mature_ = (row['pet_life_stage_at_order'] == 'mature')\n",
    "    has_allergy_ = (row['pet_allergen_list'] != 'None')\n",
    "    \n",
    "    if is_mature_ and has_allergy_:\n",
    "        return 'C. ë³µí•© ê·¸ë£¹ (ì œì™¸)' \n",
    "    elif is_mature_:\n",
    "        return 'A. ë…¸ë ¹ê²¬ ê·¸ë£¹'\n",
    "    elif has_allergy_:\n",
    "        return 'B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹'\n",
    "    else:\n",
    "        return 'D. ì¼ë°˜ ê·¸ë£¹'\n",
    "\n",
    "df_analysis['Final_Group'] = df_analysis.apply(categorize_group, axis=1)\n",
    "\n",
    "# ë³µí•© ê·¸ë£¹ì„ ì œì™¸í•œ 3ê°œ ê·¸ë£¹ë§Œ í•„í„°ë§\n",
    "target_groups = ['A. ë…¸ë ¹ê²¬ ê·¸ë£¹', 'B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹', 'D. ì¼ë°˜ ê·¸ë£¹']\n",
    "df_filtered = df_analysis[df_analysis['Final_Group'].isin(target_groups)].copy()\n",
    "\n",
    "print(f\"âœ… ìµœì¢… ë¶„ì„ ëŒ€ìƒ ê·¸ë£¹ë³„ ê°œìˆ˜:\")\n",
    "print(df_filtered['Final_Group'].value_counts().sort_index())\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c57e9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ğŸ“Š ê·¸ë£¹ë³„ ì‚¬ë£Œ ë“±ê¸‰ ì„ í˜¸ë„ (ë¹ˆë„) ###\n",
      "pet_food_tier   mid  premium  superpremium    All\n",
      "Final_Group                                      \n",
      "A. ë…¸ë ¹ê²¬ ê·¸ë£¹      4939     5270         11770  21979\n",
      "B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹      850      301          2453   3604\n",
      "D. ì¼ë°˜ ê·¸ë£¹       4056     2817          9432  16305\n",
      "All            9845     8388         23655  41888\n",
      "\n",
      "==================================================\n",
      "### ğŸ“ˆ ê·¸ë£¹ë³„ ì‚¬ë£Œ ë“±ê¸‰ ì„ í˜¸ë„ (ë¹„ìœ¨) ###\n",
      "pet_food_tier     mid premium superpremium\n",
      "Final_Group                               \n",
      "A. ë…¸ë ¹ê²¬ ê·¸ë£¹      22.47%  23.98%       53.55%\n",
      "B. ì•Œë ˆë¥´ê¸° ê·¸ë£¹     23.58%   8.35%       68.06%\n",
      "D. ì¼ë°˜ ê·¸ë£¹       24.88%  17.28%       57.85%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14820\\988320493.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  tier_proportions = tier_proportions.applymap(lambda x: f'{x:.2f}%')\n"
     ]
    }
   ],
   "source": [
    "print(\"### ğŸ“Š ê·¸ë£¹ë³„ ì‚¬ë£Œ ë“±ê¸‰ ì„ í˜¸ë„ (ë¹ˆë„) ###\")\n",
    "\n",
    "# 1. ë¹ˆë„í‘œ (Count)\n",
    "tier_counts = pd.crosstab(\n",
    "    df_filtered['Final_Group'], \n",
    "    df_filtered['pet_food_tier'], \n",
    "    margins=True # ì´ê³„ í¬í•¨\n",
    ")\n",
    "# í–‰ ì¸ë±ìŠ¤ ì •ë ¬\n",
    "tier_counts = tier_counts.reindex(target_groups + ['All'])\n",
    "print(tier_counts)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "print(\"### ğŸ“ˆ ê·¸ë£¹ë³„ ì‚¬ë£Œ ë“±ê¸‰ ì„ í˜¸ë„ (ë¹„ìœ¨) ###\")\n",
    "\n",
    "# 2. ë¹„ìœ¨í‘œ (Percentage by Group - í–‰ í•©ê³„ 100%)\n",
    "# normalize='index'ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ê·¸ë£¹ ë‚´ì—ì„œì˜ ë¹„ìœ¨ì„ ê³„ì‚°\n",
    "tier_proportions = pd.crosstab(\n",
    "    df_filtered['Final_Group'], \n",
    "    df_filtered['pet_food_tier'], \n",
    "    normalize='index' # í–‰ë³„ ë¹„ìœ¨ ê³„ì‚° (ê° ê·¸ë£¹ ë‚´ì—ì„œ 100%)\n",
    ") * 100\n",
    "\n",
    "# í–‰ ì¸ë±ìŠ¤ ì •ë ¬ ë° ì†Œìˆ˜ì  2ìë¦¬ë¡œ í¬ë§·\n",
    "tier_proportions = tier_proportions.reindex(target_groups)\n",
    "tier_proportions = tier_proportions.applymap(lambda x: f'{x:.2f}%')\n",
    "\n",
    "print(tier_proportions)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342a944",
   "metadata": {},
   "source": [
    "ë‹¤ë¥¸ê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dc6c104",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m X \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_encoded, prepend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# OLS ëª¨ë¸ ì í•© (í•™ìŠµ)\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mOLS(y, X)\n\u001b[0;32m     51\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# 5. OLS ê²°ê³¼ ì¶œë ¥ (ìš”ì²­í•˜ì‹  ì´ë¯¸ì§€ í˜•ì‹)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:921\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    918\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    919\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    920\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    922\u001b[0m                           hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:746\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    745\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 746\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    747\u001b[0m                           weights\u001b[38;5;241m=\u001b[39mweights, hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    748\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    749\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:200\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° 20,000ê°œ ëœë¤ ìƒ˜í”Œ ì¶”ì¶œ\n",
    "df = pd.read_csv('df_dropped_dry_data.csv')\n",
    "\n",
    "# ğŸ’¡ 20,000ê°œ ëœë¤ ìƒ˜í”Œ ì¶”ì¶œ\n",
    "n_samples = min(20000, len(df))\n",
    "df_sampled = df.sample(n=n_samples, random_state=42).copy()\n",
    "\n",
    "# 2. ì¢…ì† ë³€ìˆ˜ ë° ë…ë¦½ ë³€ìˆ˜ ì„¤ì •\n",
    "target_col = 'total_order_kcal' # ì¢…ì† ë³€ìˆ˜ (ì¹¼ë¡œë¦¬ ì„­ì·¨ëŸ‰)\n",
    "feature_cols = [\n",
    "    'pet_gender_pre',         # ì„±ë³„\n",
    "    'neutered_cleaned',       # ì¤‘ì„±í™” ì—¬ë¶€\n",
    "    'pet_life_pre',           # ìƒì•  ì£¼ê¸°\n",
    "    'pet_breed_size_pre',     # í¬ê¸° (ì¶”ê°€í–ˆìœ¼ë‚˜, ì²¨ë¶€ ì´ë¯¸ì§€ì—ì„œëŠ” ì œì™¸ë¨. ì´ë¯¸ì§€ì™€ ì¼ì¹˜ì‹œí‚¤ë ¤ë©´ ì œì™¸ ê°€ëŠ¥)\n",
    "    'kibble_kcal'             # ì‚¬ë£Œ ì¹¼ë¡œë¦¬\n",
    "] \n",
    "# Note: ì²¨ë¶€ ì´ë¯¸ì§€ì—ëŠ” pet_breed_size_preê°€ ì œì™¸ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "# ë§Œì•½ ì´ë¯¸ì§€ì™€ ë™ì¼í•˜ê²Œ í•˜ë ¤ë©´ feature_colsë¥¼ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œëŠ” ìš”ì²­í•˜ì‹  ë³€ìˆ˜(ì„±ë³„, ì¤‘ì„±í™”, ìƒì• ì£¼ê¸°, í¬ê¸°)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "df_reg = df_sampled[[target_col] + feature_cols].copy()\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬\n",
    "# ì¢…ì† ë³€ìˆ˜ ê²°ì¸¡ì¹˜ ì œê±°\n",
    "df_reg.dropna(subset=[target_col], inplace=True) \n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ì •ì˜ ë° ê²°ì¸¡ì¹˜ 'Unknown' ì²˜ë¦¬\n",
    "categorical_cols = [\n",
    "    'pet_gender_pre', 'neutered_cleaned', 'pet_life_pre', \n",
    "    'pet_breed_size_pre'\n",
    "]\n",
    "for col in categorical_cols:\n",
    "    if col in df_reg.columns:\n",
    "        df_reg[col] = df_reg[col].astype(str).replace('nan', 'Unknown').fillna('Unknown')\n",
    "\n",
    "# One-Hot Encoding ì ìš©\n",
    "X_encoded = pd.get_dummies(df_reg[feature_cols], drop_first=True)\n",
    "y = df_reg[target_col]\n",
    "\n",
    "# 4. statsmodels OLS ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ\n",
    "# statsmodelsëŠ” ìƒìˆ˜í•­(const)ì„ ìë™ìœ¼ë¡œ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "X = sm.add_constant(X_encoded, prepend=False) \n",
    "\n",
    "# OLS ëª¨ë¸ ì í•© (í•™ìŠµ)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# 5. OLS ê²°ê³¼ ì¶œë ¥ (ìš”ì²­í•˜ì‹  ì´ë¯¸ì§€ í˜•ì‹)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ac6173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ìƒ˜í”Œ ìˆ˜: 30000ê°œ\n",
      "----------------------------------------\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       total_order_kcal   R-squared:                       0.582\n",
      "Model:                            OLS   Adj. R-squared:                  0.581\n",
      "Method:                 Least Squares   F-statistic:                     4631.\n",
      "Date:                Thu, 13 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        13:51:36   Log-Likelihood:            -3.1408e+05\n",
      "No. Observations:               30000   AIC:                         6.282e+05\n",
      "Df Residuals:                   29990   BIC:                         6.283e+05\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "pet_gender_pre_1     -2593.8410     99.007    -26.199      0.000   -2787.899   -2399.783\n",
      "pet_neutered_pre_1     248.6934    114.001      2.182      0.029      25.247     472.139\n",
      "pet_life_pre_1        1.494e+04    225.305     66.296      0.000    1.45e+04    1.54e+04\n",
      "pet_life_pre_2        1.336e+04    215.942     61.850      0.000    1.29e+04    1.38e+04\n",
      "pet_life_pre_3        1.111e+04    245.585     45.223      0.000    1.06e+04    1.16e+04\n",
      "pet_breed_size_pre_1  5355.0654    162.731     32.907      0.000    5036.105    5674.026\n",
      "pet_breed_size_pre_2   1.43e+04    163.684     87.353      0.000     1.4e+04    1.46e+04\n",
      "pet_breed_size_pre_3  2.639e+04    172.879    152.632      0.000     2.6e+04    2.67e+04\n",
      "pet_breed_size_pre_4  3.814e+04    376.120    101.411      0.000    3.74e+04    3.89e+04\n",
      "const                -2965.4306    240.282    -12.341      0.000   -3436.394   -2494.467\n",
      "==============================================================================\n",
      "Omnibus:                     7628.194   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            66294.075\n",
      "Skew:                           0.978   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.015   Cond. No.                         13.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° 20,000ê°œ ëœë¤ ìƒ˜í”Œ ì¶”ì¶œ\n",
    "df = pd.read_csv('df_dropped_dry_data.csv')\n",
    "\n",
    "# ğŸ’¡ 20,000ê°œ ëœë¤ ìƒ˜í”Œ ì¶”ì¶œ\n",
    "n_samples = min(30000, len(df))\n",
    "df_sampled = df.sample(n=n_samples, random_state=27).copy()\n",
    "\n",
    "# 2. ì¢…ì† ë³€ìˆ˜ ë° ë…ë¦½ ë³€ìˆ˜ ì„¤ì •\n",
    "target_col = 'total_order_kcal' # ì¢…ì† ë³€ìˆ˜ (ì¹¼ë¡œë¦¬ ì„­ì·¨ëŸ‰)\n",
    "feature_cols = [\n",
    "    'pet_gender_pre',         # ì„±ë³„\n",
    "    'pet_neutered_pre',       # ì¤‘ì„±í™” ì—¬ë¶€\n",
    "    'pet_life_pre',           # ìƒì•  ì£¼ê¸°\n",
    "    'pet_breed_size_pre'     # í¬ê¸°\n",
    "               \n",
    "] \n",
    "\n",
    "df_reg = df_sampled[[target_col] + feature_cols].copy()\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬\n",
    "# ì¢…ì† ë³€ìˆ˜ ê²°ì¸¡ì¹˜ ì œê±°\n",
    "df_reg.dropna(subset=[target_col], inplace=True) \n",
    "\n",
    "# **ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ì¤‘ìš” ë‹¨ê³„:** ì¢…ì† ë³€ìˆ˜ë¥¼ ì‹¤ìˆ˜í˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜ (ë¬¸ìì—´ ë°©ì§€)\n",
    "df_reg[target_col] = pd.to_numeric(df_reg[target_col], errors='coerce').fillna(0) # ë³€í™˜ ë¶ˆê°€ ì‹œ 0ìœ¼ë¡œ ì±„ì›€\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ì •ì˜ ë° ê²°ì¸¡ì¹˜ 'Unknown' ì²˜ë¦¬\n",
    "categorical_cols = [\n",
    "    'pet_gender_pre', 'pet_neutered_pre', 'pet_life_pre', \n",
    "    'pet_breed_size_pre'\n",
    "]\n",
    "for col in categorical_cols:\n",
    "    if col in df_reg.columns:\n",
    "        df_reg[col] = df_reg[col].astype(str).replace('nan', 'Unknown').fillna('Unknown')\n",
    "\n",
    "# One-Hot Encoding ì ìš©\n",
    "X_encoded = pd.get_dummies(df_reg[feature_cols], drop_first=True)\n",
    "y = df_reg[target_col]\n",
    "\n",
    "# **ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ì¤‘ìš” ë‹¨ê³„:** ë…ë¦½ ë³€ìˆ˜ X_encodedë¥¼ ì‹¤ìˆ˜í˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜\n",
    "X_encoded = X_encoded.astype(float) \n",
    "\n",
    "# 4. statsmodels OLS ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ\n",
    "X = sm.add_constant(X_encoded, prepend=False) \n",
    "\n",
    "print(f\"ì´ ìƒ˜í”Œ ìˆ˜: {len(df_reg)}ê°œ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# OLS ëª¨ë¸ ì í•© (í•™ìŠµ)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# 5. OLS ê²°ê³¼ ì¶œë ¥ (ìš”ì²­í•˜ì‹  ì´ë¯¸ì§€ í˜•ì‹)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed16e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ìƒ˜í”Œ ìˆ˜: 30000ê°œ\n",
      "----------------------------------------\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       total_order_kcal   R-squared:                       0.582\n",
      "Model:                            OLS   Adj. R-squared:                  0.581\n",
      "Method:                 Least Squares   F-statistic:                     4631.\n",
      "Date:                Thu, 13 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:23:21   Log-Likelihood:            -3.1408e+05\n",
      "No. Observations:               30000   AIC:                         6.282e+05\n",
      "Df Residuals:                   29990   BIC:                         6.283e+05\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "pet_gender_pre_0      2593.8410     99.007     26.199      0.000    2399.783    2787.899\n",
      "pet_neutered_pre_0    -248.6934    114.001     -2.182      0.029    -472.139     -25.247\n",
      "pet_life_pre_0       -1.111e+04    245.585    -45.223      0.000   -1.16e+04   -1.06e+04\n",
      "pet_life_pre_1        3830.7239    183.000     20.933      0.000    3472.036    4189.412\n",
      "pet_life_pre_2        2249.8658    141.434     15.908      0.000    1972.650    2527.082\n",
      "pet_breed_size_pre_0 -3.814e+04    376.120   -101.411      0.000   -3.89e+04   -3.74e+04\n",
      "pet_breed_size_pre_1 -3.279e+04    360.927    -90.843      0.000   -3.35e+04   -3.21e+04\n",
      "pet_breed_size_pre_2 -2.384e+04    361.177    -66.019      0.000   -2.46e+04   -2.31e+04\n",
      "pet_breed_size_pre_3 -1.176e+04    364.859    -32.220      0.000   -1.25e+04    -1.1e+04\n",
      "const                 4.394e+04    373.826    117.537      0.000    4.32e+04    4.47e+04\n",
      "==============================================================================\n",
      "Omnibus:                     7628.194   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            66294.075\n",
      "Skew:                           0.978   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.015   Cond. No.                         24.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° 30,000ê°œ ëœë¤ ìƒ˜í”Œ ì¶”ì¶œ (ë™ì¼ ìœ ì§€)\n",
    "df = pd.read_csv('df_dropped_dry_data.csv')\n",
    "n_samples = min(30000, len(df))\n",
    "df_sampled = df.sample(n=n_samples, random_state=27).copy()\n",
    "\n",
    "# 2. ì¢…ì† ë³€ìˆ˜ ë° ë…ë¦½ ë³€ìˆ˜ ì„¤ì • (ë™ì¼ ìœ ì§€)\n",
    "target_col = 'total_order_kcal' \n",
    "feature_cols = [\n",
    "    'pet_gender_pre', 'pet_neutered_pre', 'pet_life_pre', 'pet_breed_size_pre'\n",
    "] \n",
    "df_reg = df_sampled[[target_col] + feature_cols].copy()\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬ (ë™ì¼ ìœ ì§€)\n",
    "df_reg.dropna(subset=[target_col], inplace=True) \n",
    "df_reg[target_col] = pd.to_numeric(df_reg[target_col], errors='coerce').fillna(0) \n",
    "categorical_cols = ['pet_gender_pre', 'pet_neutered_pre', 'pet_life_pre', 'pet_breed_size_pre']\n",
    "for col in categorical_cols:\n",
    "    if col in df_reg.columns:\n",
    "        df_reg[col] = df_reg[col].astype(str).replace('nan', 'Unknown').fillna('Unknown')\n",
    "\n",
    "# ğŸš¨ ìˆ˜ì •ëœ í•µì‹¬ ë¶€ë¶„:\n",
    "# 1) drop_first=Falseë¡œ ëª¨ë“  ë”ë¯¸ ë³€ìˆ˜ ìƒì„±\n",
    "X_encoded = pd.get_dummies(df_reg[feature_cols], drop_first=False)\n",
    "y = df_reg[target_col]\n",
    "\n",
    "# 2) ìˆ˜ë™ìœ¼ë¡œ 'pet_gender_pre_1' ì œê±° (ê¸°ì¤€ ê·¸ë£¹ ì„¤ì •)\n",
    "# ì´ë ‡ê²Œ í•˜ë©´ 'pet_gender_pre_0'ì˜ ê³„ìˆ˜ê°€ ìœ íš¨í•´ì§‘ë‹ˆë‹¤.\n",
    "if 'pet_gender_pre_1' in X_encoded.columns:\n",
    "    X_encoded.drop(columns=['pet_gender_pre_1'], inplace=True)\n",
    "\n",
    "# ë‹¤ì¤‘ê³µì„ ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸ ë²”ì£¼í˜• ë³€ìˆ˜ë„ í•˜ë‚˜ì”© ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# (ì´ì „ì— drop_first=Trueë¡œ ì²˜ë¦¬í–ˆë˜ ê²ƒê³¼ ë™ì¼í•œ íš¨ê³¼ë¥¼ ë‚´ê¸° ìœ„í•´)\n",
    "# ë§Œì•½ 'pet_neutered_pre_1'ì´ ê¸°ì¤€ì´ ì•„ë‹ˆë¼ 'pet_neutered_pre_0'ì„ ë³´ê³  ì‹¶ë‹¤ë©´,\n",
    "# í•´ë‹¹ ë³€ìˆ˜ë„ ì œê±°í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì  ë”ë§Œ ìš”ì²­í•˜ì…¨ìœ¼ë¯€ë¡œ ë‹¤ë¥¸ ë³€ìˆ˜ëŠ”\n",
    "# ê¸°ì¡´ 'drop_first=True' íš¨ê³¼ë¥¼ ë‚´ëŠ” ë³€ìˆ˜ë¥¼ ì œê±°í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "# (ì˜ˆì‹œ: pet_neutered_pre_0, pet_life_pre_0 ë“±)\n",
    "\n",
    "# ë§Œì•½ 'pet_neutered_pre_1'ê³¼ 'pet_life_pre_3', 'pet_breed_size_pre_4'ê°€ ê¸°ì¤€ ê·¸ë£¹ì´ ë˜ê¸¸ ì›í•œë‹¤ë©´,\n",
    "# í•´ë‹¹ ë³€ìˆ˜ë“¤ì„ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ì „ ê²°ê³¼ì˜ ë³€ìˆ˜ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ ì„ì˜ë¡œ ì œê±°í•˜ê² ìŠµë‹ˆë‹¤.)\n",
    "# í˜„ì¬ì˜ ë²”ì£¼ê°€ 0, 1, 2, 3, 4ë¡œ ë˜ì–´ìˆë‹¤ê³  ê°€ì •í•˜ê³  ê°€ì¥ ë†’ì€ ê°’ì˜ ë”ë¯¸ ë³€ìˆ˜ë“¤ì„ ì œê±°í•˜ì—¬ ê¸°ì¤€ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "variables_to_drop = [\n",
    "    'pet_neutered_pre_1', \n",
    "    'pet_life_pre_3', \n",
    "    'pet_breed_size_pre_4'\n",
    "]\n",
    "\n",
    "for col in variables_to_drop:\n",
    "    if col in X_encoded.columns:\n",
    "        X_encoded.drop(columns=[col], inplace=True)\n",
    "\n",
    "\n",
    "X_encoded = X_encoded.astype(float) \n",
    "\n",
    "# 4. statsmodels OLS ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ\n",
    "X = sm.add_constant(X_encoded, prepend=False) \n",
    "\n",
    "print(f\"ì´ ìƒ˜í”Œ ìˆ˜: {len(df_reg)}ê°œ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# OLS ëª¨ë¸ ì í•© (í•™ìŠµ)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# 5. OLS ê²°ê³¼ ì¶œë ¥\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db9766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ìƒ˜í”Œ ìˆ˜: 30000ê°œ\n",
      "----------------------------------------\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       total_order_kcal   R-squared:                       0.582\n",
      "Model:                            OLS   Adj. R-squared:                  0.581\n",
      "Method:                 Least Squares   F-statistic:                     4631.\n",
      "Date:                Thu, 13 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:27:03   Log-Likelihood:            -3.1408e+05\n",
      "No. Observations:               30000   AIC:                         6.282e+05\n",
      "Df Residuals:                   29990   BIC:                         6.283e+05\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "pet_gender_pre_0      2593.8410     99.007     26.199      0.000    2399.783    2787.899\n",
      "pet_neutered_pre_0    -248.6934    114.001     -2.182      0.029    -472.139     -25.247\n",
      "pet_life_pre_0       -1.111e+04    245.585    -45.223      0.000   -1.16e+04   -1.06e+04\n",
      "pet_life_pre_1        3830.7239    183.000     20.933      0.000    3472.036    4189.412\n",
      "pet_life_pre_2        2249.8658    141.434     15.908      0.000    1972.650    2527.082\n",
      "pet_breed_size_pre_1  5355.0654    162.731     32.907      0.000    5036.105    5674.026\n",
      "pet_breed_size_pre_2   1.43e+04    163.684     87.353      0.000     1.4e+04    1.46e+04\n",
      "pet_breed_size_pre_3  2.639e+04    172.879    152.632      0.000     2.6e+04    2.67e+04\n",
      "pet_breed_size_pre_4  3.814e+04    376.120    101.411      0.000    3.74e+04    3.89e+04\n",
      "const                 5795.6215    193.253     29.990      0.000    5416.838    6174.405\n",
      "==============================================================================\n",
      "Omnibus:                     7628.194   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            66294.075\n",
      "Skew:                           0.978   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.015   Cond. No.                         12.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° 30,000ê°œ ëœë¤ ìƒ˜í”Œ ì¶”ì¶œ\n",
    "df = pd.read_csv('df_dropped_dry_data.csv')\n",
    "n_samples = min(30000, len(df))\n",
    "df_sampled = df.sample(n=n_samples, random_state=27).copy()\n",
    "\n",
    "# 2. ì¢…ì† ë³€ìˆ˜ ë° ë…ë¦½ ë³€ìˆ˜ ì„¤ì •\n",
    "target_col = 'total_order_kcal' \n",
    "feature_cols = [\n",
    "    'pet_gender_pre', 'pet_neutered_pre', 'pet_life_pre', 'pet_breed_size_pre'\n",
    "] \n",
    "df_reg = df_sampled[[target_col] + feature_cols].copy()\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬\n",
    "df_reg.dropna(subset=[target_col], inplace=True) \n",
    "df_reg[target_col] = pd.to_numeric(df_reg[target_col], errors='coerce').fillna(0) \n",
    "categorical_cols = ['pet_gender_pre', 'pet_neutered_pre', 'pet_life_pre', 'pet_breed_size_pre']\n",
    "for col in categorical_cols:\n",
    "    if col in df_reg.columns:\n",
    "        df_reg[col] = df_reg[col].astype(str).replace('nan', 'Unknown').fillna('Unknown')\n",
    "\n",
    "# ğŸš¨ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„: One-Hot Encoding ë° ê¸°ì¤€ ê·¸ë£¹ ì„¤ì •\n",
    "# 1) drop_first=Falseë¡œ ëª¨ë“  ë”ë¯¸ ë³€ìˆ˜ ìƒì„±\n",
    "X_encoded = pd.get_dummies(df_reg[feature_cols], drop_first=False)\n",
    "y = df_reg[target_col]\n",
    "\n",
    "# 2) ìš”ì²­í•˜ì‹  ê¸°ì¤€ ë³€ìˆ˜ë“¤ì„ ìˆ˜ë™ìœ¼ë¡œ ì œê±° (ê¸°ì¤€ ê·¸ë£¹ ì„¤ì •)\n",
    "# ì œê±°í•  ë³€ìˆ˜ ëª©ë¡\n",
    "reference_vars_to_drop = [\n",
    "    'pet_gender_pre_1',       # ê¸°ì¤€ 1: ì  ë” 1\n",
    "    'pet_neutered_pre_1',     # ê¸°ì¤€ 2: ì¤‘ì„±í™” 1\n",
    "    'pet_life_pre_3',         # ê¸°ì¤€ 3: í« ìƒì• ì£¼ê¸° 3\n",
    "    'pet_breed_size_pre_0'    # ê¸°ì¤€ 4: í« ë¸Œë¦¬ë“œ ì‚¬ì´ì¦ˆ 0\n",
    "]\n",
    "\n",
    "for col in reference_vars_to_drop:\n",
    "    if col in X_encoded.columns:\n",
    "        X_encoded.drop(columns=[col], inplace=True)\n",
    "\n",
    "# ë°ì´í„° íƒ€ì… ì •ë¦¬\n",
    "X_encoded = X_encoded.astype(float) \n",
    "\n",
    "# 4. statsmodels OLS ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ\n",
    "X = sm.add_constant(X_encoded, prepend=False) \n",
    "\n",
    "print(f\"ì´ ìƒ˜í”Œ ìˆ˜: {len(df_reg)}ê°œ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# OLS ëª¨ë¸ ì í•© (í•™ìŠµ)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# 5. OLS ê²°ê³¼ ì¶œë ¥\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1c96092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "34108    1\n",
       "34109    1\n",
       "34110    1\n",
       "34111    0\n",
       "34112    0\n",
       "Name: pet_neutered_pre, Length: 34113, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pet_neutered_pre']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
