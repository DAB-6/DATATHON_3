{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**가설**\n"
      ],
      "metadata": {
        "id": "JJ2AdIuDvfM4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYsgTQddvbzB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import shap\n",
        "\n",
        "# ===== 1) 데이터 로드 =====\n",
        "file_path = \"C:/Users/Monte/Desktop/데이터톤/online_shoppers_intention.csv\"  # VS Code면 실제 경로로 교체\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "features = [\"ProductRelated\", \"ProductRelated_Duration\", \"PageValues\", \"ExitRates\"]\n",
        "target = \"Revenue\"\n",
        "\n",
        "# ===== 2) 가설 검정 (Welch's t-test + Cohen's d) =====\n",
        "def cohens_d(a, b):\n",
        "    na, nb = len(a), len(b)\n",
        "    sa, sb = np.var(a, ddof=1), np.var(b, ddof=1)\n",
        "    sp = np.sqrt(((na - 1) * sa + (nb - 1) * sb) / (na + nb - 2))\n",
        "    return (np.mean(a) - np.mean(b)) / sp if sp != 0 else np.nan\n",
        "\n",
        "buyers = df[df[target] == True]\n",
        "non_buyers = df[df[target] == False]\n",
        "\n",
        "rows = []\n",
        "for feat in features:\n",
        "    a, b = buyers[feat].astype(float).values, non_buyers[feat].astype(float).values\n",
        "    t, p = stats.ttest_ind(a, b, equal_var=False)  # Welch\n",
        "    d = cohens_d(a, b)\n",
        "    rows.append({\n",
        "        \"Variable\": feat,\n",
        "        \"Buyers_Mean\": np.mean(a),\n",
        "        \"NonBuyers_Mean\": np.mean(b),\n",
        "        \"Mean_Diff\": np.mean(a) - np.mean(b),\n",
        "        \"Welch_t\": t,\n",
        "        \"p_value\": p,\n",
        "        \"Cohen_d\": d\n",
        "    })\n",
        "\n",
        "hypo_df = pd.DataFrame(rows).sort_values(\"p_value\")\n",
        "print(\"=== Welch’s t-test + Cohen’s d (분류 리포트 없이) ===\")\n",
        "print(hypo_df.round(4))\n",
        "\n",
        "# ===== 3) SHAP 계산을 위한 최소 모델 =====\n",
        "# (SHAP은 모델이 필요하므로, 설명 전용으로 로지스틱을 적합하지만 성능 지표는 출력 X)\n",
        "X = df[features]\n",
        "y = df[target].astype(int)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ===== 4) 변수 기여 요약 (계수표) =====\n",
        "coef_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Coefficient\": model.coef_[0],\n",
        "    \"AbsImportance\": np.abs(model.coef_[0])\n",
        "}).sort_values(\"AbsImportance\", ascending=False)\n",
        "\n",
        "print(\"\\nLogistic Coefficients\")\n",
        "print(coef_df)\n",
        "\n",
        "# ===== 5) SHAP Summary Plot =====\n",
        "# np.bool 패치 (일부 shap 버전 호환)\n",
        "if not hasattr(np, \"bool\"): np.bool = np.bool_\n",
        "\n",
        "explainer = shap.Explainer(model, X_train, feature_names=features)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# ===== 초록색 계열 색상 적용 =====\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    pd.DataFrame(X_test, columns=features),\n",
        "    feature_names=features,\n",
        "    cmap=\"Greens\",     #\n",
        "    show=True\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# ===== 로지스틱 회귀 적합도 검증 =====\n",
        "X_const = sm.add_constant(X_scaled)\n",
        "logit_model = sm.Logit(y, X_const)\n",
        "result = logit_model.fit(disp=False)\n",
        "\n",
        "# McFadden’s pseudo R² 계산\n",
        "llf_model = result.llf\n",
        "llf_null = result.llnull\n",
        "pseudo_r2 = 1 - (llf_model / llf_null)\n",
        "\n",
        "print(f\"\\n=== McFadden's pseudo R² ===\")\n",
        "print(f\"R² = {pseudo_r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "f97WmAYKvxkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델링**\n"
      ],
      "metadata": {
        "id": "2Hk3ylZ8v2Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# === 데이터 불러오기 ===\n",
        "df = pd.read_csv(\"C:/Users/Monte/Desktop/데이터톤/online_shoppers_intention.csv\")\n",
        "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
        "\n",
        "# === 필요한 변수만 ===\n",
        "cols = [\"productrelated\", \"productrelated_duration\", \"exitrates\", \"pagevalues\"]\n",
        "data = df[cols].dropna().copy()\n",
        "\n",
        "# === 1. 로그 변환 ===\n",
        "data[\"prd_log\"] = np.log1p(data[\"productrelated\"])\n",
        "data[\"dur_log\"] = np.log1p(data[\"productrelated_duration\"])\n",
        "data[\"pv_log\"]  = np.log1p(data[\"pagevalues\"])\n",
        "\n",
        "# === 2. 스케일링 ===\n",
        "sc1 = StandardScaler()\n",
        "sc2 = RobustScaler()\n",
        "\n",
        "data[\"prd_scaled\"] = sc1.fit_transform(data[[\"prd_log\"]])\n",
        "data[\"dur_scaled\"] = sc1.fit_transform(data[[\"dur_log\"]])\n",
        "data[\"exit_scaled\"] = sc2.fit_transform(data[[\"exitrates\"]])\n",
        "data[\"pv_scaled\"] = sc2.fit_transform(data[[\"pv_log\"]])\n",
        "\n",
        "# === 3. 최종 feature set ===\n",
        "X = data[[\"prd_scaled\", \"dur_scaled\", \"exit_scaled\", \"pv_scaled\"]]\n",
        "\n",
        "# === 4. KMeans 및 Silhouette ===\n",
        "for k in range(2, 11):\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=100)\n",
        "    labels = km.fit_predict(X)\n",
        "    sil = silhouette_score(X, labels)\n",
        "    print(f\"k={k}, silhouette={sil:.3f}\")\n"
      ],
      "metadata": {
        "id": "5VduUmvqv4g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 최적 K 정하고 클러스터링\n",
        "k_opt = 5\n",
        "km = KMeans(n_clusters=k_opt, random_state=42, n_init=50)\n",
        "labels = km.fit_predict(X)\n",
        "data[\"cluster\"] = labels\n",
        "\n",
        "# 시각화 시작\n",
        "custom_colors = [\"#25C486\", \"#919191\", \"#2FA241\", \"#005E39\", \"#022020\"]\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=50)\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=labels, palette=custom_colors, s=20, alpha=0.7)\n",
        "plt.title(\"t-SNE Visualization of Clusters (K=5)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jXl57DJVv_N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 군집별 빠른 프로파일 ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 군집 크기/비율\n",
        "print(\"\\n[Cluster size/share]\")\n",
        "cnt = data[\"cluster\"].value_counts().sort_index()\n",
        "print(pd.DataFrame({\"count\": cnt, \"share\": (cnt/len(data)).round(3)}))\n",
        "\n",
        "# 원본 변수 기준 요약 (평균/중앙값)\n",
        "cols_orig = [\"productrelated\", \"productrelated_duration\", \"pagevalues\", \"exitrates\"]\n",
        "print(\"\\n[Cluster profile: mean / median]\")\n",
        "summary = data.groupby(\"cluster\")[cols_orig].agg([\"mean\",\"median\"]).round(3)\n",
        "print(summary)\n",
        "\n",
        "# 간단 파생지표: 페이지당 체류시간, PageValues>0 비율\n",
        "eps = 1e-9\n",
        "tmp = data.copy()\n",
        "tmp[\"dur_per_page\"] = tmp[\"productrelated_duration\"] / (tmp[\"productrelated\"] + eps)\n",
        "tmp[\"pv_pos\"] = (tmp[\"pagevalues\"] > 0).astype(int)\n",
        "\n",
        "print(\"\\n[Derived metrics]\")\n",
        "derived = tmp.groupby(\"cluster\").agg(\n",
        "    dur_per_page_median=(\"dur_per_page\", \"median\"),\n",
        "    pv_pos_rate=(\"pv_pos\", \"mean\"),          # 비율\n",
        "    exit_median=(\"exitrates\", \"median\")\n",
        ").round(3)\n",
        "print(derived)"
      ],
      "metadata": {
        "id": "q3ldq1GNwBSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# === 1) 데이터 로드 ===\n",
        "file_path = \"C:/Users/Monte/Desktop/데이터톤/online_shoppers_intention.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# === 2) VisitorType → 신규 방문자 여부 변수화 ===\n",
        "df[\"is_new\"] = (df[\"VisitorType\"].str.strip().str.lower() == \"new_visitor\").astype(int)\n",
        "\n",
        "# === 3) 클러스터 라벨 연결 (이전에 KMeans 했던 결과 사용)\n",
        "# KMeans 수행 시 dropna()로 행이 줄었으므로 index 맞춰야 함\n",
        "df_clustered = df.loc[df.index.isin(data.index)].copy()\n",
        "df_clustered[\"cluster\"] = labels\n",
        "\n",
        "# === 4) 클러스터별 신규 방문자 비율 계산 ===\n",
        "summary = df_clustered.groupby(\"cluster\")[\"is_new\"].agg([\"mean\", \"count\", \"sum\"])\n",
        "summary[\"new_ratio(%)\"] = (summary[\"mean\"] * 100).round(2)\n",
        "print(\"=== 클러스터별 신규 방문자 비율 ===\")\n",
        "print(summary)\n",
        "\n",
        "# === 5) 카이제곱 검정 (전체 군집 간 비교) ===\n",
        "contingency = pd.crosstab(df_clustered[\"cluster\"], df_clustered[\"is_new\"])\n",
        "chi2, p, dof, exp = stats.chi2_contingency(contingency)\n",
        "print(f\"\\n[카이제곱 검정] χ²={chi2:.3f}, df={dof}, p-value={p:.5f}\")\n",
        "if p < 0.05:\n",
        "    print(\"→ 유의함: 클러스터 간 신규 방문자 비율에 유의한 차이가 있습니다.\")\n",
        "else:\n",
        "    print(\"→ 유의하지 않음: 클러스터 간 신규 방문자 비율 차이는 통계적으로 동일합니다.\")\n",
        "\n",
        "# === 6) Cluster 3 vs 4 두 집단 간 비율 검정 (선택) ===\n",
        "cluster_a, cluster_b = 3, 4\n",
        "a_success = df_clustered.loc[df_clustered[\"cluster\"] == cluster_a, \"is_new\"].sum()\n",
        "a_n = df_clustered.loc[df_clustered[\"cluster\"] == cluster_a, \"is_new\"].count()\n",
        "b_success = df_clustered.loc[df_clustered[\"cluster\"] == cluster_b, \"is_new\"].sum()\n",
        "b_n = df_clustered.loc[df_clustered[\"cluster\"] == cluster_b, \"is_new\"].count()\n",
        "\n",
        "z, p_z = proportions_ztest([a_success, b_success], [a_n, b_n])\n",
        "print(f\"\\n[두 군집 비율검정] Cluster {cluster_a} vs {cluster_b}: z={z:.3f}, p-value={p_z:.5f}\")\n",
        "if p_z < 0.05:\n",
        "    print(f\"→ Cluster {cluster_a}와 {cluster_b}의 신규 방문자 비율은 유의하게 다릅니다.\")\n",
        "else:\n",
        "    print(f\"→ Cluster {cluster_a}와 {cluster_b}의 신규 방문자 비율은 통계적으로 유의하지 않습니다.\")\n"
      ],
      "metadata": {
        "id": "DtBhNuhdwDW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# === Kruskal–Wallis 비모수 검정 ===\n",
        "groups = [df_clustered.loc[df_clustered[\"cluster\"] == c, \"specialday\"] for c in sorted(df_clustered[\"cluster\"].unique())]\n",
        "H, p = stats.kruskal(*groups)\n",
        "\n",
        "print(f\"Kruskal–Wallis H = {H:.3f}, p = {p:.5f}\")"
      ],
      "metadata": {
        "id": "-m3hPifjwJp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# === (1) 군집 크기 ===\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=cnt.index, y=cnt.values, palette=\"tab10\")\n",
        "plt.title(\"Cluster Size Distribution\", fontsize=14)\n",
        "plt.xlabel(\"Cluster\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# === (2) 원본 변수 프로파일 (평균 / 중앙값 비교) ===\n",
        "mean_df = summary.xs('mean', level=1, axis=1)\n",
        "median_df = summary.xs('median', level=1, axis=1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "sns.heatmap(mean_df, annot=True, fmt=\".2f\", cmap=\"Greens\", ax=axes[0])\n",
        "axes[0].set_title(\"Cluster Mean Profile\", fontsize=14)\n",
        "\n",
        "sns.heatmap(median_df, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=axes[1])\n",
        "axes[1].set_title(\"Cluster Median Profile\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === (3) 파생지표 시각화 (평균 vs 중앙값 비교) ===\n",
        "# 중앙값 버전은 이미 derived에 있고, 평균 버전 추가\n",
        "derived_mean = tmp.groupby(\"cluster\").agg(\n",
        "    dur_per_page_mean=(\"dur_per_page\", \"mean\"),\n",
        "    pv_pos_rate=(\"pv_pos\", \"mean\"),\n",
        "    exit_mean=(\"exitrates\", \"mean\")\n",
        ").round(3)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "\n",
        "# ---- 중앙값 기준 ----\n",
        "sns.barplot(x=derived.index, y=derived[\"dur_per_page_median\"], ax=axes[0, 0], palette=\"Blues\")\n",
        "axes[0, 0].set_title(\"Median Duration per Page\")\n",
        "\n",
        "sns.barplot(x=derived.index, y=derived[\"pv_pos_rate\"], ax=axes[0, 1], palette=\"Greens\")\n",
        "axes[0, 1].set_title(\"PageValues>0 Rate (Median Base)\")\n",
        "\n",
        "sns.barplot(x=derived.index, y=derived[\"exit_median\"], ax=axes[0, 2], palette=\"Reds\")\n",
        "axes[0, 2].set_title(\"Median Exit Rate\")\n",
        "\n",
        "# ---- 평균 기준 ----\n",
        "sns.barplot(x=derived_mean.index, y=derived_mean[\"dur_per_page_mean\"], ax=axes[1, 0], palette=\"Blues\")\n",
        "axes[1, 0].set_title(\"Mean Duration per Page\")\n",
        "\n",
        "sns.barplot(x=derived_mean.index, y=derived_mean[\"pv_pos_rate\"], ax=axes[1, 1], palette=\"Greens\")\n",
        "axes[1, 1].set_title(\"PageValues>0 Rate (Mean Base)\")\n",
        "\n",
        "sns.barplot(x=derived_mean.index, y=derived_mean[\"exit_mean\"], ax=axes[1, 2], palette=\"Reds\")\n",
        "axes[1, 2].set_title(\"Mean Exit Rate\")\n",
        "\n",
        "for ax in axes.flat:\n",
        "    ax.set_xlabel(\"Cluster\")\n",
        "    ax.set_ylabel(\"Value\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "C8W4Pge4wQPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# === 클러스터링에 사용하지 않은 변수 선택 ===\n",
        "excluded_cols = [\"ProductRelated\", \"ProductRelated_Duration\", \"PageValues\", \"ExitRates\", \"cluster\"]\n",
        "cols_to_check = [c for c in df.columns if c not in excluded_cols]\n",
        "\n",
        "# 데이터프레임 병합 (cluster 포함)\n",
        "data_vis = df.copy()\n",
        "data_vis[\"cluster\"] = data[\"cluster\"].values  # 이미 클러스터링 결과가 있다고 가정\n",
        "\n",
        "# === 1) 수치형 변수 (mean 기준 barplot) ===\n",
        "num_cols = data_vis.select_dtypes(include=[np.number, \"bool\"]).columns.difference([\"cluster\"])\n",
        "fig, axes = plt.subplots(len(num_cols)//3 + 1, 3, figsize=(15, 4*(len(num_cols)//3 + 1)))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(num_cols):\n",
        "    sns.barplot(data=data_vis, x=\"cluster\", y=col, estimator=np.mean, palette=\"tab10\", ax=axes[i])\n",
        "    axes[i].set_title(f\"{col} (mean)\", fontsize=11)\n",
        "    axes[i].set_xlabel(\"Cluster\")\n",
        "    axes[i].set_ylabel(\"Mean Value\")\n",
        "\n",
        "for j in range(i+1, len(axes)):\n",
        "    axes[j].set_visible(False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === 2) 범주형 변수 (비율 기반 barplot) ===\n",
        "cat_cols = data_vis.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "for col in cat_cols:\n",
        "    plt.figure(figsize=(7,4))\n",
        "    prop = pd.crosstab(data_vis[\"cluster\"], data_vis[col], normalize=\"index\")\n",
        "    prop.plot(kind=\"bar\", stacked=True, colormap=\"tab20\", ax=plt.gca())\n",
        "    plt.title(f\"{col} Distribution by Cluster\")\n",
        "    plt.ylabel(\"Proportion\")\n",
        "    plt.xlabel(\"Cluster\")\n",
        "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "qGhzI_2LwQt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# 0) 데이터 로드가 이미 되어 있다고 가정: df\n",
        "#    (필요시) df = pd.read_csv(\"/mnt/data/online_shoppers_intention.csv\")\n",
        "\n",
        "df_work = df.copy()\n",
        "\n",
        "# 1) 군집 라벨 자동 확보\n",
        "labels = None\n",
        "# 1-a) data['cluster'] 재사용\n",
        "if \"data\" in globals():\n",
        "    try:\n",
        "        if isinstance(data, pd.DataFrame) and \"cluster\" in data.columns and len(data) == len(df_work):\n",
        "            labels = data[\"cluster\"].to_numpy()\n",
        "            print(\"[INFO] Using cluster labels from data['cluster']\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# 1-b) 전역 라벨 후보 변수 재사용\n",
        "if labels is None:\n",
        "    for name in [\"labels\", \"y_cluster\", \"clusters\", \"km_labels\"]:\n",
        "        if name in globals():\n",
        "            cand = globals()[name]\n",
        "            try:\n",
        "                arr = np.asarray(cand).reshape(-1)\n",
        "                if len(arr) == len(df_work):\n",
        "                    labels = arr\n",
        "                    print(f\"[INFO] Using cluster labels from global '{name}'\")\n",
        "                    break\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "# 1-c) 없으면 즉석 KMeans로 생성 (가능한 피처만 선택)\n",
        "if labels is None:\n",
        "    base_feats_pref = [\"ProductRelated\", \"ProductRelated_Duration\", \"PageValues\", \"ExitRates\"]\n",
        "    feats = [c for c in base_feats_pref if c in df_work.columns]\n",
        "    if len(feats) < 2:\n",
        "        # 숫자형에서 임의로 확장(최대 6개)\n",
        "        extra = [c for c in df_work.select_dtypes(include=[np.number]).columns if c not in feats]\n",
        "        feats = list(dict.fromkeys(feats + extra))[:6]\n",
        "    X = df_work[feats].replace([np.inf, -np.inf], np.nan).fillna(df_work[feats].median())\n",
        "    Xs = StandardScaler().fit_transform(X)\n",
        "    km = KMeans(n_clusters=5, random_state=42, n_init=50)\n",
        "    labels = km.fit_predict(Xs)\n",
        "    print(f\"[INFO] Created on-the-fly KMeans labels (k=5) using features: {feats}\")\n",
        "\n",
        "# df_work에 cluster 부여(원본 df는 그대로 보존)\n",
        "df_work[\"cluster\"] = labels\n",
        "\n",
        "# 2) 파생변수 제외한 “원본 변수” 선택\n",
        "exclude_keywords = [\"dur_per\", \"per_\", \"ratio\", \"flag\", \"log\", \"score\", \"scaled\", \"z\", \"pos\"]\n",
        "base_cols = [\n",
        "    c for c in df_work.select_dtypes(include=[\"number\", \"bool\"]).columns\n",
        "    if c.lower() != \"cluster\" and not any(k in c.lower() for k in exclude_keywords)\n",
        "]\n",
        "\n",
        "if not base_cols:\n",
        "    raise ValueError(\"파생변수를 제외하고 그릴 수 있는 수치/불리언 기본 변수가 없습니다.\")\n",
        "\n",
        "# 3) 클러스터별 평균 계산\n",
        "profile = df_work.groupby(\"cluster\")[base_cols].mean()\n",
        "\n",
        "# 4) 막대그래프 함수 (군집 하나용)\n",
        "def plot_cluster_bar(profile_df, cluster_id, palette=\"Greens\"):\n",
        "    if cluster_id not in profile_df.index:\n",
        "        print(f\"[WARN] Cluster {cluster_id} not found. Available: {list(profile_df.index)}\")\n",
        "        return\n",
        "    s = profile_df.loc[cluster_id].sort_values(ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=s.index, y=s.values, palette=palette)\n",
        "    plt.title(f\"Cluster {cluster_id} — Mean of Base Variables\", fontsize=14)\n",
        "    plt.xticks(rotation=75)\n",
        "    plt.ylabel(\"Mean Value\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
        "\n",
        "    # 값 라벨(소수 3자리)\n",
        "    for i, v in enumerate(s.values):\n",
        "        plt.text(i, v + (0.01 if v >= 0 else -0.02), f\"{v:.3f}\",\n",
        "                 ha='center', va='bottom' if v >= 0 else 'top', fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 5) Cluster 3, 4 각각 출력\n",
        "plot_cluster_bar(profile, 3, palette=\"Greens_r\")\n",
        "plot_cluster_bar(profile, 4, palette=\"Greens_r\")\n"
      ],
      "metadata": {
        "id": "2yFqgPkWwUo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}